1. 所谓处理器架构，或者处理器编程架构，是指一整套的硬件结构，以及与之相适应的工作状态，这其中的灵魂部分就是一种设计理念，决定了处理器的应用环境和工作模式，也决定了软件开发人员如何在这种模式下解决实际问题。架构内的资源对程序员来说是可见的、可访问的，受程序的控制以改变处理器的运行状态；非架构的资源取决于具体的硬件实现。
2. 处理器架构实际上是不断扩展的，新处理器必须延续旧的设计思路，并保持兼容性和一致性，同时还会有所扩充和增强。
3. Intel 32 位处理器架构简称 IA-32（Intel Architecture，32-bit)，是以 1978 年的 8086 处理器为基础发展起来的。在那个时候，他们只是想造一款特别牛的处理器，也没考虑到架构。尽管那些人是专家，但和我们一样不是千里眼，这是很正常的。
4. 正如我们已经知道的，8086 有 20 根地址线，可以寻址 1MB 内存。但是，它内部的寄存器是 16 位的，无法在程序中访问整个 1MB 内存。所以，它也是第一款支持内存分段模型的处理器。还
有， 8086 处理器只有一种工作模式，即实模式。当然，在那时，还没有如模式这一说。由于 8086 处理器的成功，推动着 Intel 公司不断地研发更新的处理器，32 位的时代就这样到来了。到目前为止，到底有多少种类型，我也说不清楚。尽管 8086 是 16 位的处理器，但它也是 32 位架构内的一部分。原因在于，32 位的处理器架构是从 8086 那里发展来的，是基于 8086 的，具有延续性和兼容性。
5. 就我们曾经用过的产品而言，32 位的处理器有 32 根地址线，数据线的数量是 32 根或者 64 根。特别是最近最新的处理器，都是 64 根。因此，它可以访问 2<sup>32</sup>，即 4GB 的内存，而且每次可以读写连续的 4 字节或者 8 字节，这称为双字（Double Word）或者 4 字（Quad Word）访问。当然，如果你要按字节或者字来访问内存，也是允许的。
6. 我总说，处理器虽小，功能却异常复杂。要想把 32 位处理器的所有功能都解释清楚，不是一件简单的事情。它不单单是地址线和数据线的扩展，实际上还有更多的部分，包括高速缓存、流水线、浮点处理部件、多处理器（核）管理、多媒体扩展、乱序执行、分支预测、虚拟化、温度和电源管理等。在这本书里，我的一个基本原则是，如果你不能讲清楚，干脆就不要提它。因此，我只讲那些现在用得上的东西。
7. 可以在 32 位处理器上运行 16 位处理器上的软件。但是，它并不是 16 位处理器的简单增强。事实上，32 位处理器有自己的 32 位工作模式，在本书中，32 位模式特指 32 位保护模式。在这种模式下，可以完全、充分地发挥处理器的性能。同时，在这种模式下，处理器可以使用它全部的 32 根地址线，能够访问 4GB 内存。在 32 位模式下，为了生成 32 位物理地址，处理器需要使用 32 位的指令指针寄存器。为此，32 位处理器扩展了 IP，使之达到 32 位，即 EIP。当它工作在 16 位模式下时，依然使用 16 位的 IP；工作在 32 位模式下时，使用的是全部的 32 位 EIP。和往常一样，即使是在 32 位模式下，EIP 寄存器也只由处理器内部使用，程序中是无法直接访问的。对 IP 和 EIP 的修改通常是用某些指令隐式进行的，这些指令包括 JMP、CALL、RET 和 IRET 等等。
8. 另外，在 16 位处理器中，标志寄存器 FLAGS 是 16 位的，在 32 位处理器中，扩展到了 32 位，低 16 位和原先保持一致。关于 EFLAGS 中的各个标志位，将在后面的章节中逐一介绍。
9. （平坦模型）在32 位模式下，对内存的访问从理论上来说不再需要分段，因为它有 32 根地址线，可以自由访问任何一个内存位置。但是，IA-32 架构的处理器是基于分段模型的，因此，32 位处理器依然需要以段为单位访问内存，即使它工作在 32 位模式下。不过，它也提供了一种变通的方案，即，只分一个段，段的基地垃是 0x00000000，段的长度(大小)是 4GB。在这种情况下，可以视为不分段，即平坦模型（Flat Mode）。
10. 每个程序都有属于自己的内存空间。在 16 位模式下，一个程序可以自由地访问不属于它的内存位置，甚至可以对那些地方的内容进行修改。这当然是不安全的，也不合法，但却没有任何机制来限制这种行为。在 32 位模式下，处理器要求在加载程序时，先定义该程序所拥有的段，然后允许使用这些段。定义段时，除了基地址（起始地址）外，还附加了段界限、特权级别、类型等属性。当程序访问一个段时，处理器将用固件实施各种检查工作，以防止对内存的违规访问。
11. （段选择子、段选择器、段描述符高速缓存区）如下图所示，在 32 位模式下，传统的段寄存器，如 CS、SS、DS、ES，保存的不再是16位段基地址，而是段的选择子，即，用于选择所要访问的段，因此，严格地说，它的新名字叫做段选择器。除了段选择器之外，每个段寄存器还包括一个不可见部分，称为描述符高速缓存器，里面有段的基地址和各种访问属性。这部分内容程序不可访问，由处理器自动使用。最后。32 位处理器增加了两个额外的段寄存器 FS 和 GS。对于某些复杂的程序来说，多出两个段寄存器可能会令它们感到高兴。
![image](https://user-images.githubusercontent.com/32811372/208301360-996b33ae-dec3-4f07-b19f-d561b44a89f4.png)

# 工作模式
## 8086 实模式（16 位处理器）
1. 8086 具有 16 位的段寄存器、指令指针寄存器和通用寄存器（CS、SS、DS、ES、IP、AX、BX、CX、DX、SI、DI、BP、SP)，因此，我们称它为 16 位的处理器。尽管它可以访问 1MB 的内存，但是只能分段进行，而且由于只能使用 16 位的段内偏移量，故段的长度最大只能是 64KB。8086 只有一种工作模式，即实模式。当然，这个名称是后来才提出来的。

## 80286（16 位处理器、兼容 8086 实模式、支持 16 位保护模式）
1. 1982 年的时候，Intel 公司推出了 80286 处理器。这也是一款 16 位的处理器，大部分的寄存器都和 8086 处理器一样。因此，80286 和 8086 一样，因为段寄存器是 16 位的，而且只能使用 16 位的偏移地址，在实模式下只能使用 64KB 的段；尽管它有 24 根地址线，理论上可以访问 2<sup>24</sup>，即 16MB 的内存，但依然只能分成多个段来进行。
2. 但是，80286 和 8086 不一样的地方在于，它第一次提出了保护模式的概念。在保护模式下，段寄存器中保存的不再是段地址，而是段选择子，真正的段地址位于段寄存器的描述符高速缓存中，是 24 位的。因此，运行在保护模式下的 80286 处理器可以访问全部 16MB 内存。
3. 80286 处理器访问内存时，不再需要将段地址左移，因为在段寄存器的描述符高速缓存器中有 24 位的段物理基地址。这样一来，段可以位于 16MB 内存空间中的任何位置，而不再限于低端 1MB 范围内，也不必非得是位于 16 字节对齐的地方。不过，由于 80286 的通用寄存器是 16 位的，只能提供 16 位的偏移地址，因此，和 8086 一样，即使是运行在保护模式下，段的长度依然不能超过 64KB。对段长度的限制妨碍了 80286 处理器的应用，这就是 16 位保护模式很少为人所知的原因。
3. 80286 实模式等同于 8086 模式，在本书中，实模式和 16 位保护模式统称 16 位模式。在 16 位模式下，数据的大小是 8 位或者 16 位的；控制转移和内存访问时，偏移量也是 16 位的。

## 80386（32 位处理器、兼容 8086 实模式、兼容 80286 的 16 位保护模式、支持 32 位保护模式、支持虚拟 8086 模式）
1. 1985 年的 80386 处理器是 Intel 公司的第一款 32 位产品，而且获得了极大成功，是后续所有 32 位产品的基础。本书中的绝大多数例子，都可以在 80386 上运行。
2. 和 8086/80286 不同，80386 处理器的寄存器是 32 位的，而且拥有 32 根地址线，可以访问 2<sup>32</sup>，即 4GB 的内存。
3. 80386，以及所有后续的 32 位处理器，都兼容实模式，可以运行实模式下的 8086 程序。而且，在刚加电时，这些处理器都自动处于实模式下，此时，它相当于一个非常快速的 8086 处理器。只有在进行一番设置之后，才能运行在保护模式下。
4. （平坦模式）在保护模式下，所有的 32 位处理器都可以访问多达 4GB 的内存，它们可以工作在分段模型下，每个段的基地址是 32 位的，段内偏移量也是 32 位的，因此，段的长度不受限制。在最典型的情况下，可以将整个 4GB 内存定义成一个段来处理，这就是所谓的平坦模式。在平坦模式下，可以执行 4GB 范围内的控制转移，也可以使用 32 位的偏移量访问任何 4GB 范围内的任何位置。32 位保护模式兼容 80286 的 16 位保护模式。
5. （虚拟 8086 模式）除了保护模式，32 位处理器还提供虚拟 8086 模式（V86 模式），在这种模式下，IA-32 处理器被模拟成多个 8086 处理器并行工作。V86 模式是保护模式的一种，可以在保护模式下执行多个 8086 程序。传统上，要执行 8086 程序，处理器必须工作在实模式下。在这种情况下，为 32 位保护模式写的程序就不能运行。但是，V86 模式提供了让它们在一起同时运行的条件。V86 模式曾经很有用，因为在那个时候，8086 程序很多，而 32 位应用程序很少，这个过渡期是必需的。现在，这种工作模式已经基本无用了。
6. 在本书中，32 位模式特指 IA-32 处理器上的 32 位保护模式。不存在所谓的 32 位实模式，实模式的概念实质上就是 8086 模式。

# 地址
## 逻辑地址 & 有效地址
1. 为 IA-32 处理器编程，访问内存时，需要在程序中给出段地址和偏移量，因为分段是 1A-32 架构的基本特征之一。传统上，段地址和偏移地址称为逻辑地址，偏移地址叫做有效地址（Effctive
Address, EA)，在指令中给出有效地址的方式叫做寻址方式（Addressing Mode)（比如：基址寻址、基址变址寻址等）。

## 物理地址 & 线性地址
1. 段的管理是由处理器的段部件负责进行的，段部件将段地址和偏移地址相加，得到访问内存的地址。一般来说，段部件产生的地址就是物理地址。
2. （为什么要有分页机制）IA-32 处理器支持多任务。在多任务环境下，任务的创建需要分配内存空间；当任务终止后，还要回收它所占用的内存空间。在分段模型下，内存的分配是不定长的，程序大时，就分配一大块内存；程序小时，就分配一小块。时间长了，内存空间就会碎片化，就有可能出现一种情况：内存空间是有的，但都是小块，无法分配给某个任务。为了解决这个问题，IA-32 处理器支持分页功能，分页功能将物理内存空间划分成逻辑上的页。页的大小是固定的，一般为 4KB，通过使用页，可以简化内存管理。
3. 分段机制，是为了支持单一任务代码段和数据段的分离管理、也是为了支持多个任务的同时运行；
4. 分页机制，只有分段机制，多任务同时运行时容易产生内存碎片问题，通过使用分页机制，可以弱化该问题；
5. 如下图所示，当页功能开启时，段部件产生的地址就不再是物理地址了，而是线性地址(Linear Address)，线性地址还要经页部件转换后，才是物理地址。
![image](https://user-images.githubusercontent.com/32811372/208304607-86b834a0-cd42-4837-8d1a-101dca8b9ff0.png)
6. 线性地址的概念用来描述任务的地址空间。如上图所示，IA-32 处理器上的每个任务都拥有 4GB 的虚拟内存空间，这是一段长 4GB 的平坦空间，就像一段平直的线段，因此叫线性地址空间。相应地，由段部件产生的地址，就对应着线性地址空间上的每一个点，这就是线性地址。

# 现代处理器的结构和特点
## 流水线
1. 处理器的每一次更新换代，都会增加若干新特性，这是很自然的。同时我们也会发现，老软件在新的处理器上跑得更快。这里面的原因很简单，处理器的设计者总是在想尽办法加快指令的执行。
2. 早在 8086 时代，处理器就已经有了指令预取队列。当指令执行时，如果总线是空闲的（没有访同内存的操作)，就可以在指令执行的同时预取指令并提前译码，这种做法是有效的，能大大加快程序的执行速度。
3. 处理器可以做很多事情，换言之，能够执行各种不同的指令，完成不同的功能，但这些事情大都不会在一个时钟周期内完成。执行一条指令需要从内存中取指令、译码、访问操作数和结果，并进行移位、加法、减法、乘法以及其他任何需要的操作。为了提高处理器的执行效率和速度，可以把一条指令的执行过程分解成若干个细小的步骤。并分配给相应的单元来完成。各个单元的执行是独立的、并行的。如此一来，各个步骤的执行在时间上就会重叠起来，这种执行指令的方法就是流水线（Pipe-Line）技术。
4. 比如，一条指令的执行过程分为取指令、译码和执行三个步骤，而且假定每个步骤都要花1个时钟周期，那么，如图 10-4 所示，如果采用顺序执行，则执行三条指令就要花 9 个时钟周期，每 3 个时钟周期才能得到一条指令的执行结果；如果采用 3 级流水线，则执行这三条指令只需 5 个时钟周期，每隔一个时钟周期就能得到一条指令的执行结果。
![image](https://user-images.githubusercontent.com/32811372/208339255-e67f7ecc-5ed0-4503-be05-8643b41d9197.png)
5. 一个简单的流水线其实不过如此，但是，它仍有很大的改进空间。原因很简单，指令的执行过程仍然可以继续细分。一般来说，流水线的效率受执行时间最长的那一级的限制，要缩短各级的执行时间，就必须让每一级的任务减少，与此同时，就需要把一些复杂的任务再进行分解。比如，2000 年之后推出的 Pentium 4 处理器采用了 NetBurst 微结构，它进一步分解指令的执行过程，采用了 31 级超深流水线。

## 高速缓存
1. 影响处理器速度的另一个因素是存储器。从处理器内部向外看，它们分别是寄存器、内存和硬盘。当然，现在有的计算机已经用上了固态磁盘。
2. 寄存器的速度是最快的，原因在于它使用了触发器，这是一种利用反馈原理制作的存储电路，在《穿越计算机的迷雾》那本书里，介绍得很清楚。触发器的工作速度是纳秒（ns）级别的，当然也可以用来作为内存的基本单元，即静态存储器（SRAM），缺点是成本太高，价格也不菲。所以，制作内存芯片的材料一般是电容和单个的晶体管，由于电容需要定时刷新，使得它的访问速度变得很慢，通常是几十个纳秒。因此，它也获得了一个恰当的名字：动态存储器(DRAM)，我们所用的内存芯片，大部分都是 DRAM。最后，硬盘是机电设备，是机械和电子的混合体，它的速度最慢，通常在毫秒级（ms）。
3. 在这种情况下，因为需要等待内存和硬盘这样的慢速设备，处理器便无法全速运行。为了缓解这一矛盾，高速缓存（Cache）技术应运而生。高速缓存是处理器与内存（DRAM）之间的一个静态存储器，容量较小，但速度可以与处理器匹配。
4. 高速缓存的用处源于程序在运行时所具有的局部性规律。首先，程序常常访问最近刚刚访问过的指令和数据，或者与它们相邻的指令和数据。比如，程序往往是序列化地从内存中取指令执行的，循环操作往往是执行一段固定的指令。当访问数据时，要访问的数据通常都被安排在一起；其次，一旦访问了某个数据，那么，不久之后，它可能会被再次访问。
5. 利用程序运行时的局部性原理，可以把处理器正在访问和即将访问的指令和数据块从内存调入高速缓存中。于是，每当处理器要访问内存时，首先检索高速缓存。如果要访问的内容已经在高速缓存中，那么，很好，可以用极快的速度直接从高速缓存中取得，这称为命中（Hit)；否则，称为不中（miss)。在不中的情况下，处理器在取得需要的内容之前必须重新装载高速缓存，而不只是直接到内存中去取那个内容。高速缓存的装载是以块为单位的，包括那个所需数据的邻近内容。为此，需要额外的时间来等待块从内存载入高速缓存，在该过程中所损失的时间称为不中惩罚（miss penalty)。
6. 高速缓存的复杂性在于，每一款处理器可能都有不同的视线。在一些复杂的处理器内部，会存在多级 Cache，分别应用于各个独立的执行部件。

## 乱序执行
1. 为了实现流水线技术，需要将指令拆分成更小的可独立执行部分，即拆分成微操作（micro-operations)，简写为 μops。
2. 有些指令非常简单，因此只需要一个微操作。如：
``` asm
add eax,ebx
```
3. 再比如：
``` asm
add eax,[mem]
```
可以拆分成两个微操作，一个用于从内存中读取数据并保存到临时寄存器，另一个用于将 EAX 寄存器和临时寄存器中的数值相加。
4. 再举个例子，这条指令:
``` asm
add [mem],eax
```
可以拆分成三个微操作，一个从内存中读数据，一个执行相加的动作。第 3 个用于将相加的结果写回到内存中。
5. 一旦将指令拆分成微操作，处理器就可以在必要的时候乱序执行（Out-Of-Order Execution）程序。考虑以下例子：
``` asm
mov eax,[mem1]
shl eax,5
add eax,[mem2]
mov [mem3],eax
```
这里，指令 `add eax,[mem2]` 可以拆分为两个微操作。如此一来，在执行逻辑左移指令的同时，处理器可以提前从内存中读取 mem2 的内容。典型地，如果数据不在高速缓存中（不中)，那么处理器在获取 mem1 的内容之后，会立即开始获取 mem2 的内容，与此同时，shl 指令的执行早就开始了。
将指令拆分成微操作，也可以使得栈的操作更有效率。考虑以下代码片断：
``` asm
push eax
call func
```
这里，push eax 指令可以拆分成两个微操作，即可以表述为以下的等价形式：
``` asm
sub esp,4
mov [esp],eax
```
这就带来了一个好处，即使 EAX寄存器的内容还没有准备好，微操作 `sub esp,4` 也可以执行。call 指令执行时需要在当前栈中保存返回地址，在以前，该操作只能等待 push eax 指令执行结束，因为它需要 ESP 的新值。感谢微操作，现在，call 指令在微操作 `sub esp,4` 执行结束时就可以无延迟地立即开始执行。

## 寄存器重命名
1. 考虑以下例子:
``` asm
mov eax,[mem1]
shl eax,3
mov [mem2],eax
mov eax,[mem3]
add eax,2
mov [mem4],eax
```
以上代码片断做了两件事，但互不相干：将 mem1 里的内容左移 3 次（乘以 8)，并将 mem3 里的内容加 2。如果我们为最后三条指令使用不同的寄存器，那么将更明显地看出这两件事的无关性。并且，事实上，处理器实际上也是这样做的。处理器为最后三条指令使用了另一个不同的临时寄存器，因此，左移（乘法）和加法可以并行地处理。

2. IA-32 架构的处理器只有 8 个 32 位通用寄存器，但通常都会被我们全部派上用场（甚至还觉得不够)。因此，我们不能奢望在每个计算当中都使用新的寄存器。不过，在处理器内部，却有大量的临时寄存器可用，处理器可以重命名这些寄存器以代表一个逻辑寄存器，比如 EAX。
3. 寄存器重命名以一种完全自动和非常简单的方式工作。每当指令写逻辑寄存器时，处理器就为那个逻辑寄存器分配一个新的临时寄存器。再来看一个例子：
``` asm
mov eax,[mem1]
mov ebx,[mem2]
add ebx,eax
shl eax,3
mov [mem3],eax
mov [mem4],ebx
```
假定现在 mem1 的内容在高速缓存里，可以立即取得，但 mem2 的内容不在高速缓存中。这意味着，左移操作可以在加法之前开始（使用临时寄存器代替 EAX)。为左移的结果使用一个新的临时寄存器，其好处是 EAX 寄存器中仍然是以前的内容，它将一直保持这个值，直到 EBX 寄存器中的内容就绪，然后同它一起做加法运算。如果没有寄存器重命名机制，左移操作将不得不等待从内存中读取 mem2 的内容到 EBX 寄存器以及加法操作完成。在所有的操作都完成之后，那个代表 EAX 寄存器最终结果的临时寄存器的内容被写入真实的 EAX 寄存器，该处理过程称为引退（Retirement)。

4. 所有通用寄存器，栈指针、标志、浮点寄存器，甚至段寄存器都有可能被重命名。
